\section{Introduction}
% par 1: Introduction to the Problem
% Purpose: Define the problem and explain its significance.
%  What is the problem, what is the challenge, and why is it important

\begin{displayquote}
[T]he many, who are not as individuals excellent men, nevertheless can, when they have come together, be better than the few best people, not individually but collectively, just as feasts to which many contribute are better than feasts provided at one person's expense.

\begin{flushright}
-- Aristotle, \textit{Politics} III
\end{flushright}
\end{displayquote}

Collective intelligence (CI) relies on aggregating individual inputs to generate high-quality outcomes, under the assumption that individuals~\textit{can} express their preferences accurately and that these expressions can be meaningfully synthesized. However, traditional survey tools—such as Likert scales—struggle to elicit both rankings and intensity of preferences, particularly in scenarios where individuals must allocate limited resources across multiple options. Similarly, democratic aggregation tools such as one-person-one-vote (1p1v) often suffer from the tyranny of the majority, failing to capture the strength of minority preferences. These limitations pose a challenge for CI systems, which depend on precise preference elicitation to facilitate collective decision-making.

Recent studies have explored alternative approaches, including Quadratic Surveys (QS), a survey tool designed to elicit preferences more accurately than Likert scales~\cite{chengCanShowWhat2021, quarfoot2017quadratic, cavaille2024cares}. QS requires participants to "purchase" $k$ votes for an option, where the cost follows a quadratic function, $k^2$~\cite{quarfoot2017quadratic, chengCanShowWhat2021}, thereby forcing trade-offs within a fixed budget. By introducing an economic constraint, QS aims to balance individual expressiveness with meaningful aggregation, making it particularly relevant for CI applications that seek to capture both preference intensity and diversity. While QS has demonstrated promising results, the specific mechanisms that contribute to its effectiveness remain insufficiently understood.

% ================================ %
% par 2: Approaches to Address the Challenges
% Purpose: Describe the existing approaches related to the problem.
% Key Questions:
%  - What are some broad approaches to addressing these challenges?
%  - Do not go into detail about related work but give an idea of the major themes in related work.
Prior work comparing QS to Likert scales has primarily focused on evaluating its effectiveness in preference elicitation, but these studies often conflate rankings and ratings. QS is one of the few survey tools capable of eliciting both simultaneously, making it difficult to isolate how well each measure aligns with participant behavior independently. Additionally, while QS has been extensively compared to Likert scales, fewer studies have examined its relationship to a similar class of surveys—constant sum surveys (CSS)—which employ a linear cost function. Since QS's advantage over Likert scales is often attributed to the forced trade-offs introduced by its budget constraint, researchers have questioned whether a simpler linear cost structure could achieve similar results. Understanding whether a linear cost structure can replicate QS's effects is crucial for CI applications, where balancing cognitive effort and preference accuracy is key. While recent investigations have explored the cognitive challenges QS imposes on participants, they do not clarify whether the quadratic cost function itself is necessary or whether a linear alternative could reduce complexity while maintaining effectiveness.


% ================================ %
% par 3: Your Proposal
% Purpose: Present your main ideas and proposed solution.
% Key Question:
%  - What are you proposing? Provide a sketch of the major ideas.

To address these gaps, we build on the open data and software from~\citet{chengCanShowWhat2021} and conduct four additional experiments exploring variations of constant sum surveys, as well as a version of QS without a budget constraint. We design two new evaluation measures to assess how different survey mechanisms—including Likert scales, QS with varying budgets, constant sum surveys with different budgets, and unlimited QS—perform in capturing participant preferences. Given the role of CI in leveraging individual judgments for collective insights, this study seeks to clarify the trade-offs between different preference elicitation mechanisms. More formally, we pose the following research questions:

\begin{itemize}
\item [\textbf{RQ1.}] How effectively does QS capture participant preferences when analyzing pairwise comparisons and preference intensities, as opposed to using a high-dimensional similarity measure (e.g., cosine similarity) to compare QS results with participant behaviors?
\item [\textbf{RQ2.}] How do the two foundational components of the Quadratic Voting mechanism—fixed budget and quadratic cost—individually and jointly impact its effectiveness in eliciting individual preferences?
\end{itemize}

% ================================ %
% par 4: Main Findings
% Purpose: Summarize the key findings from your work.
% Key Question:
%  - What are the main findings?

To investigate these questions, we recruited 202 MTurk participants using stratified sampling to match the U.S. census population. Participants completed either a QS without a budget or a constant sum survey (CS) with varying budget constraints, using a modified version of the open-source software from~\citet{chengCanShowWhat2021}. We constructed two Bayesian models to compare these results with the publicly available dataset from~\citet{illinoisdatabankIDB-1928463}. Our results reveal that ...

% ================================ %
% par 5: Main Contributions
% Purpose: Identify and explain the primary contributions of your work.
% Key Structure:
%  1. Line 1: Identify your contribution—conceptualization, framework, interface, algorithm, etc.
%  2. Line 2: Contrast your contribution with prior work.
%  3. Line 3: Explain how you accomplished your contribution.
%  4. Line 4: Emphasize the impact of the contribution—why should anyone care?

\paragraph{Contributions}
We contribute to the collective intelligence community by further validating QS's ability to elicit individual preferences in comparison to Likert scales and constant sum surveys. Our findings demonstrate that the budget constraint alone does not fully explain QS's superior alignment with participant behavior; rather, the quadratic cost function, which introduces diminishing marginal utility, plays a critical role in shaping preference expression. By empirically demonstrating that QS requires both quadratic costs and budget constraints to achieve its intended effect, we provide deeper insights into designing preference elicitation mechanisms for CI applications. This study reinforces the theoretical foundation of quadratic voting~\cite{lalley2016quadratic} while broadening its implications for collective decision-making.

