\section{Experiment Design}
\label{sec:experiment}
This section outlines the experimental design, adapted from~\citet{chengCanShowWhat2021}, and approved by the university's Institutional Review Board (IRB).

\subsection{Participant Recruitment}
The study recruited 202 Amazon Mechanical Turk (MTurk) participants using stratified sampling. We screened participants by age, gender, income, and education to ensure demographic balance and randomly assigned them to conditions. This approach aimed to mitigate demographic imbalances in participation~\cite{redmilesHowWellMy2019}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{content/image/whyqs_exp_flow.pdf}
    \caption{Experiment overview. Our study covers the dotted box beneath, mirroring prior research only differing the type of surveys involved during the opinion collection section. The bar below highlights the four parts of the study: sampling, opinion collection, filler task, and the behavioral task.}
    \label{fig:experiment}
\end{figure}

\subsection{Experiment Design}
To ensure comparability with the prior study~\cite{chengCanShowWhat2021}, we followed the same between-subject experimental design and modified open-source software to introduce two new condition types, yielding four additional experimental datasets. The subsections below highlight key procedural modifications, while the choice of survey methods and the donation task are justified by prior research. Figure~\ref{fig:experiment} illustrates how our study fits within the broader experimental flow established by previous work.

\paragraph{Additional Experimental Conditions}
We introduced four new experimental conditions, grouped into two categories: UQS and LS. In the UQS condition, we removed the budget constraint to isolate the effect of the quadratic cost function. In the LS conditions, we replaced the quadratic cost function with a linear one and further subdivided these into three levels based on budget size:

\begin{itemize} 
    \item LS18: A small-budget Linear Survey with 18 credits
    \item LS54: A medium-budget Linear Survey with 54 credits
    \item LS162: A large-budget Linear Survey with 162 credits
\end{itemize}

Following prior work, we allocated two credits per option to match the expressiveness of a 5-point Likert scale, allowing participants to indicate moderate intensity in either direction. With nine options, this yielded 18 credits for the LS18 condition. We then scaled the budgets using $O(K)$, $O(K^{1.5})$, and $O(K^2)$ to generate LS18, LS54, and LS162, respectively—for example, $2 \times 9^{1.5} = 54$ in LS54.

\subsubsection{Survey content}
The study frames the survey as a public resource allotment task, where participants express preferences across 9 societal issues such as education, environment, or health. Participants would express their degree of preferences in number of votes, positive or negatively under the mechanism of UQS or LS.

\subsubsection{Surveying process and interface}
Participants in both groups were first introduced to the survey and how to use it via a video tutorial that we recorded. To assure their understanding of these mechanism, participants were asked to complete a quiz with 5 multiple-choice questions. Participants were required to answer at least 3 questions correctly to continue with the study. We altered the questions based on the survey mechanisms. The interface for both UQS and LS are shown in~\Cref{fig:extended_interface}.

% create a side by side figure using subfigure

\begin{figure}
    \centering
    \begin{subfigure}{0.47\textwidth}
        \centering
        \includegraphics[width=\textwidth]{content/image/linear.png}
        \caption{Linear Survey (QS) Interface, each additional vote is $1$ credit}
        \label{fig:qs_interface}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.47\textwidth}
        \centering
        \includegraphics[width=\textwidth]{content/image/uqs.png}
        \caption{Unlimited Quadratic Survey (UQS) Interface, each additional vote is $n^2$ credits but does not have a budget constraint}
        \label{fig:css_interface}
    \end{subfigure}
    \caption{Survey interfaces for the two additional conditions. Both images are screenshots of the playground for participants to experience the surveying method before completing the actual survey tasks on societal issues.}
    \label{fig:extended_interface}
\end{figure}


\subsubsection{Filler task and donation}
After the survey, participants completed a filler task to prevent direct association with the issues and the charities listed on the donation task page. Participants 

\subsubsection{Debrief, and Compensation}
After the study, participants have a chance to read about the study's real purpose on the debrief page. Participants were compensated with \$1.50 for their time, and they were informed that they would receive an additional \$0.50 if they completed the study.

\subsubsection{Integrating prior data}
\citet{chengCanShowWhat2021} was the first study to evaluate the effectiveness of QS in relation to human behavior, offering an open dataset and open-source software that we replicated and extended. Their dataset contains 219 MTurk participants: 56 completed a Likert scale survey, 107 completed the QS36 survey, 108 completed QS108, and 111 completed QS324.

To facilitate our analysis, we differentiate between the number of votes allocated to each option (used in the original QS analysis) and the total credits spent on each option, which reflects the actual cost incurred under the quadratic cost function. To make this distinction clear, we refer to the credit-spent measures as QSC36, QSC108, and QSC324, corresponding to the cost-based modeling of QS36, QS108, and QS324 conditions.

Altogether, this study compares the elicited preferences from QS (vote-based), QSC (cost-based), LS (linear cost), UQS (QS without budget constraints), and Likert scale surveys, using participants' actual donation behavior as a behavioral baseline. These conditions are summarized in~\Cref{tbl:experiment_cond}.


\begin{table}[h]
    \centering
    \begin{tabular}{@{}lllp{9cm}@{}}
        \toprule
        \textbf{Condition} & \textbf{Budget} & \textbf{Cost Function} & \textbf{Description} \\
        \midrule
        Likert & – & – & A 5-point traditional ordinal-scale survey. \\ 
        \midrule
        Donation & – & – & Incentive-compatible donation task used as behavioral benchmark for validating expressed preferences. \\
        \midrule
        QS36   & 36   & Quadratic & \multirow{3}{9cm}{QS conditions with three different budgets ($O(K)$, $O(K^{1.5})$, $O(K^2)$). Participants expressed preferences by allocating votes, where the cost of each vote increased quadratically, deducted from the budget.} \\
        QS108  & 108  & Quadratic & \\
        QS324  & 324  & Quadratic & \\
        \midrule
        QSC36  & 36   & Quadratic & \multirow{3}{9cm}{Credits that participants contributed per option. Using the results from QS, QSC reflects the actual cost incurred per option to reflect perceived intensity of preference and explore alignment with donation outcomes.} \\
        QSC108 & 108  & Quadratic & \\
        QSC324 & 324  & Quadratic & \\
        \midrule
        LS18   & 18   & Linear    & \multirow{3}{9cm}{Linear-cost versions of QS with budgets scaled as $O(K)$, $O(K^{1.5})$, and $O(K^2)$. Participants expressed preferences by allocating votes, where the cost of each vote increased linearly, deducted from the budget.} \\
        LS54   & 54   & Linear    & \\
        LS162  & 162  & Linear    & \\
        \midrule
        UQS    & Unlimited & Quadratic & QS without a budget where participants expressed preferences by allocating votes, where the cost of each vote increased quadratically but there is not budget that they ahere to. \\
        \bottomrule
    \end{tabular}
    \caption{Summary of experimental and behavioral conditions, their cost structures, budget levels, and modeling purposes.}
    \label{tbl:experiment_cond}
\end{table}

\subsection{Quantitative Measures: Ordinal and Interval Measures}
\label{sec:quantitative_measures}
Two prior empirical studies compared elicited survey responses with behavioral outcomes—such as donation~\cite{chengCanShowWhat2021,cavaille2024cares} or letter length~\cite{cavaille2024cares}—as proxies for individual preferences. ~\citet{chengCanShowWhat2021} employed a Bayesian model to compute cosine similarity, which measures the alignment between participants' stated preferences and observed behaviors. ~\citet{cavaille2024cares} used linear regression to estimate the differences between stated preferences and behavioral outcomes.

While cosine similarity is useful for high-dimensional data, it poses interpretative challenges. For example, high alignment might result from large angular differences between vectors with identical rankings, whereas low alignment could stem from small angular differences between completely misaligned rankings. Linear regression, by contrast, primarily captures correlations rather than causal relationships, limiting its explanatory power. Additionally, since each behavioral measure (e.g., donation, letter writing) represents a distinct task, comparing relative preferences across options within the same participant is difficult.

Thus, in this study, we draw from prior literature to compare multi-option survey instruments by breaking down and evaluating QS’s ability to elicit ordinal and interval scales separately~\cite{collewetPreferenceEstimationPoint2023}. We construct Bayesian models for both analyses, considering their transparency in interpreting posterior distributions beyond binary thresholds~\cite{mcelreath2018statistical, kay2016researcher}. We compare five different conditions and describe the models in the following subsections.

\subsubsection{Pairwise Ordinal Measures}
\label{sec:ordinal_measures}
\input{content/2.1_ordinal_model.tex}

\subsubsection{Interval Measures}
\label{sec:interval_measures}
\input{content/2.2_intensity_model.tex}
