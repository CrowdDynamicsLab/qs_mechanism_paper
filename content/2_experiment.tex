\section{Experiment Design}
\label{sec:experiment}

This section describes the experiment design. The study was approved by the university's Institutional Review Board (IRB). 

\subsection{Participant Recruitment}
This study recruited 202 Amazon Mechanical Turk (MTurk) participants using stratified sampling. The system screened participants based on their age, gender, household income, and education level to assure a balanced demographic within each experiment condition while randomly assigning participants to these conditions. This approach aimed to mitigate imbalanced participation demographics~\cite{redmilesHowWellMy2019}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{content/image/whyqs_exp_flow.pdf}
    \caption{Experiment overview. Our study covers the dotted box beneath, mirroring prior research only differing the type of surveys involved during the opinion collection section. The bar below highlights the four parts of the study: sampling, opinion collection, filler task, and the behavioral task.}
    \label{fig:experiment}
\end{figure}

\subsection{Experiment Design}
To ensure comparable data with prior study~\cite{chengCanShowWhat2021}, this study followed the same between-subject experimental design and altered the open sourced software to create two more conditions, creating four new experimental data. We highlight key procedures and alternations we made to the original methodology and redirect choice of surveying method, and the choice of donation as a task, to prior studies for justification. Figure~\ref{fig:experiment} shows how our study fits into the prior work and the overall experiment flow.

\paragraph{Additional Experimental Conditions}
We added four additional experimental conditions presented as two groups, UQS or the LS. The LS group was further divided into three conditions with different budgets:

\begin{itemize}
    \item Unlimited QS (UQS): Participants experience quadratic costs without budget constraints, isolating the effect of cost scaling.
    \item Linear Survey with 18 Credits (LS18): A small-budget linear-cost condition testing the effect of budget constraints.
    \item Linear Survey with 54 Credits (LS54): A medium-budget version allowing greater expressiveness.
    \item Linear Survey with 162 Credits (LS162): A high-budget condition assessing whether increased budgets improve alignment.
\end{itemize}

UQS's isolates the effect of budget constraints while LS isolates the effect of the quadratic cost function cost function. Participants assigned to the LS condition completed two randomly selected LS conditions.

To match the expressiveness of 5-point Likert scales, we allocated 2 credits per option, allowing participants to express moderate intensity in either direction. With 9 options, this yields 18 credits for the LS18 condition. We then scaled budgets using $O(K)$, $O(K^{1.5})$, and $O(K^2)$ to create LS18, LS54, and LS162, respectivelyâ€”for example, $2 \times 9^{1.5}=54$ in LS54. This isolates the effect of budget constraints under a linear cost structure.

% The UQS condition , while the LS conditions isolate the effect of budget constraints. Together, these conditions allow for a direct comparison of cost mechanisms in preference elicitation. As mentioned in~\Cref{sec:related_works_force_choice}, QS with linear cost function is slightly different then CSS where participants do not need to allocate all their provided credits, however, that effectively equals to an additional ``no response'' option on CSS, thus, here we denote these variations as CSS. 



\subsubsection{Survey content}
The study frames the survey as a public resource allotment task, where participants express preferences across 9 societal issues such as education, environment, or health. Participants would express their degree of preferences in number of votes, positive or negatively under the mechanism of UQS or LS.

\subsubsection{Surveying process and interface}
Participants in both groups were first introduced to the survey and how to use it via a video tutorial that we recorded. To assure their understanding of these mechanism, participants were asked to complete a quiz with 5 multiple-choice questions. Participants were required to answer at least 3 questions correctly to continue with the study. We altered the questions based on the survey mechanisms. The interface for both UQS and LS are shown in~\Cref{fig:extended_interface}.

% create a side by side figure using subfigure

\begin{figure}
    \centering
    \begin{subfigure}{0.47\textwidth}
        \centering
        \includegraphics[width=\textwidth]{content/image/linear.png}
        \caption{Linear Survey (QS) Interface, each additional vote is $1$ credit}
        \label{fig:qs_interface}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.47\textwidth}
        \centering
        \includegraphics[width=\textwidth]{content/image/uqs.png}
        \caption{Unlimited Quadratic Survey (UQS) Interface, each additional vote is $n^2$ credits but does not have a budget constraint}
        \label{fig:css_interface}
    \end{subfigure}
    \caption{Survey interfaces for the two additional conditions. Both images are screenshots of the playground for participants to experience the surveying method before completing the actual survey tasks on societal issues.}
    \label{fig:extended_interface}
\end{figure}


\subsubsection{Filler task and donation}
After the survey, participants completed a filler task to prevent direct association with the issues and the charities listed on the donation task page. Participants 

\subsubsection{Debrief, and Compensation}
After the study, participants have a chance to read about the study's real purpose on the debrief page. Participants were compensated with \$1.50 for their time, and they were informed that they would receive an additional \$0.50 if they completed the study.

\subsection{Quantitative Measures: Ordinal and Interval Measures}
\label{sec:quantitative_measures}
Two prior empirical studies compared elicited survey responses with behavioral outcomes, such as donation~\cite{chengCanShowWhat2021,cavaille2024cares} or letter length~\cite{cavaille2024cares}, as proxies for individual preferences. ~\citet{chengCanShowWhat2021} employed a Bayesian model to compute cosine similarity, measuring the alignment between participants' stated preferences and observed behaviors. ~\citet{cavaille2024cares} used linear regression to estimate the differences between the two.

While cosine similarity is useful for high-dimensional data, it presents interpretative challenges. For example, high alignment might result from large angular differences between vectors with identical rankings, while low alignment could stem from small angular differences between completely misaligned rankings. Linear regression, on the other hand, primarily captures correlations rather than causal relationships, limiting its explanatory power. Additionally, since each behavioral measure (e.g., donation, letter writing) represents a distinct task, it is difficult to compare relative preferences across options within the same participant.

Thus, in this study, we draw from prior literature when comparing multi-option survey instruments in breaking down and evaluating QS's ability to elicit the ordinal and interval scales seperately~\cite{collewetPreferenceEstimationPoint2023}. We construct Bayesian models for both analysis considering its transparent nature for interpretatinf posterior distributions beyond binary thresholds~\cite{mcelreath2018statistical, kay2016researcher}. We compared 5 different conditions summarized in~\Cref{tbl:experiment_cond} and describe the models in the following subsections.



\subsubsection{Pairwise Ordinal Measures}
\label{sec:ordinal_measures}
\input{content/2.1_ordinal_model.tex}

\subsubsection{Interval Measures}
\label{sec:interval_measures}
\input{content/2.2_intensity_model.tex}
