Following the ordinal comparisons,~\textbf{intensity model} assesses how effectively instruments capture the magnitude of preference differences between options. This model evaluates how well an instrument reflects varying degrees of preference along a continuum.

\paragraph{Aligning the variables} Constructing a intensity model to compare the different instruments is not trivial, since elicited values are continuous and others are ordinal. We took a conservative approach and model likert scale and QS votes as ordinal values, especually when it is not clear whether participants considering the varying costs associated with different votes for the latter. In contrast, LS reflects incremental additions on a scale, and UQS does not have a limit; hence, both are treated as continuous. Rather than solely using final outcomes from each instrument, we also incorporated the cost of votes for QSs, assuming each dollar increment shares the same ``monetary'' value.

For instruments with bounded, continous budgets (e.g., \textit{QSC\_36}, \textit{QSC\_108}, \textit{QSC\_324}) and linear surveys (\textit{LS\_36}, \textit{LS\_108}, \textit{LS\_324}), we project vote differences onto the $[0,1]$ interval. Since UQS lacks fixed bounds, we normalize the vote difference $V$ between two options $t_1$ and $t_2$ over the $k'$ options that the participant voted on:

\begin{equation}
    \text{Vote\_diff}_{UQS} 
    = (V_{t1} - V_{t2})/\textstyle\sum V_{k'}
\end{equation}
and apply the same normalization for UQS credits.

\paragraph{Projecting Ordinal values} 
To facilitate a direct comparison, we transform the ordinal results into an unobserved latent continuous variable using a Dirichlet-based ``cutpoint'' transformation. Specifically, for each instrument, we derive $K$ discrete ordinal \emph{difference} categories. For example, QS36 has 17 possible difference categories (ranging from $-8$ to $+8$)\footnote{Here, 36 credits can generate a largest difference of 5 votes vs.\ $-3$ votes.}. We then sample
\(\boldsymbol{\alpha}\) from a Dirichlet$(\mathbf{1}\cdot\delta)$ prior, where each of its $K-1$ positive components sums to 1:

\begin{equation}
    \boldsymbol{\alpha} \sim \mathrm{Dirichlet}\bigl(\mathbf{1}\cdot \delta\bigr)
\end{equation}

We moded the distribution with $\delta=2$ as a weakly informative prior over the latent cutpoints. We pad this vector so that $\alpha_0 = 0$, then map each category $k$ to a latent continuous value:

\begin{equation}
    x_{\mathrm{latent}}^{(k)} = \sum_{j=0}^{k} \alpha_j.
\end{equation}

As $k$ increases, $x_{\mathrm{latent}}^{(k)}$ grows but remains within the $[0,1]$ interval, effectively assigning each ordinal category a continuous value. 

\paragraph{Projecting Donations} Finally, since donation amounts also vary by participant, we remove those who donated nothing and normalize each donation difference by the participant's total donation, mirroring our UQS approach. With these transformations, all experimental variables and outcomes lie in $[0,1]$, forming the basis for a \emph{hierarchical normal} model.

\paragraph{Modeling the outcome}
We seek to capture how an instrument \emph{predicts} the donation difference $y_i$ between two options. Conditional on a mean $\mu_i$, the outcome follows a normal distribution:

\begin{equation}
    \label{eq:intensity_normal}
    y_i \sim \mathcal{N}(\mu_i, \sigma_i).
\end{equation}

where $C_i$ denotes the survey instrument (Likert, QS, QS cost, LS, or UQS). We place a prior $\mathcal{N}(0,0.2)$ on the intercept $\beta_{c}[C_i]$ for each condition and use a non-centered parameterization~\cite{mcelreath2018statistical} to model condition-specific slopes:

\begin{equation}
    \beta_{\text{vote}}[C_i]
    \;=\;
    \beta_{\text{vote}\,\text{bar}}
    + \sigma_{\text{vote}}\,\eta_{\text{vote}}[C_i],
    \quad
    \beta_{\text{vote}\,\text{bar}}
    \sim
    \mathcal{N}(0,1),
    \quad
    \sigma_{\text{vote}}
    \sim
    \mathrm{Uniform}(0,1),
    \quad
    \eta_{\text{vote}}[C_i]
    \sim
    \mathcal{N}(0,1).
\end{equation}

These slopes, together with each instrument's intercept, determine how normalized vote differences $\text{VoteDiff}_i$ (either transformed ordinal or inherently continuous) map onto $y_i$. We also include an order effect $\beta_{o}[O_i]$ and topic intercepts $\beta_{t}[T_{1i}]$ and $\beta_{t}[T_{2i}]$, each following a non-centered prior with a Normal hyper-mean and a Uniform hyper-scale. Putting these elements together, the linear predictor is:

\begin{equation}
    \label{eq:intensity_linpred}
    \mu_i
    =
    \beta_{c}[C_i]
    +
    \beta_{\text{vote}}[C_i] \cdot \text{VoteDiff}_i
    +
    \beta_{o}[O_i]
    +
    \beta_{t}[T_{1i}]
    +
    \beta_{t}[T_{2i}].
\end{equation}

Each condition is then assigned its own standard deviation $\sigma_i=\beta_{\sigma}[C_i]$, where $\beta_{\sigma}[C_i]$ is drawn from an $\mathrm{Exponential}(1)$ prior. Hence, different instruments exhibit distinct variance in donation differences.

A hierarchical Bayesian approach ties all these parameters together via a non-centered parameterization:

\begin{equation}
    x_i
    =
    \mu_x
    + \sigma_x \cdot \eta_i,
    \qquad
    \eta_i
    \sim
    \mathcal{N}(0,1).
\end{equation}

Here, $\mu_x$ and $\sigma_x$ define the group-level mean and scale for each parameter type, and $x_i$ represents condition intercepts, slopes, order intercepts, or topic intercepts. By integrating condition, vote difference, order, and topic effects into a single hierarchical normal framework, our model provides a structured way to analyze how different survey instruments capture the intensity of preference differences.
