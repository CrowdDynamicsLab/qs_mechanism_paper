The first analysis, termed~\textbf{sign analysis}, examines how well the outcomes from different instruments align with participants' donation behavior, specifically in terms of preference ordering. To achieve this, we constructed pairwise comparisons between survey instrument outcomes and actual donation amounts.

After removing participants who made zero donations, each observation $y_i$ indicates whether the ordering preference expressed through the instrument matches the order based on actual donations between two specific options. This creates a binary alignment outcome, modeled as a Bernoulli distribution (Equation~\ref{eq:ordinal_model_overall}):

\begin{equation}
    \label{eq:ordinal_model_overall}
    y_i \sim \text{Bernoulli}(\theta_i)
\end{equation}

The probability of alignment, $\theta_i$, is defined through a logit link function (Equation~\ref{eq:ordinal_model_logit}), controlling for several experimental variables:

\begin{equation}
    \label{eq:ordinal_model_logit}
    \text{logit}(\theta_i) = \alpha + \beta_c[C_i] + \beta_o[O_i] + \beta_p[P_i] + \beta_t[T_{1i}] + \beta_t[T_{2i}]
\end{equation}

Here, the variables represent different experimental conditions and their characteristics. Specifically, $C_i$ indicates the survey instrument used, involving eight distinct conditions: three variants of Quadratic Surveys (QS) with varying budgets, three variants with linear cost structures with varying budgets, a traditional Likert scale survey, and an unlimited-budget version of Quadratic Surveys. The variable $O_i$ represents the order in which participants completed the surveys if they experienced both versions, capturing potential learning or ordering effects. The variable $P_i$ indicates whether a participant's survey response aligns with their previous response if they completed more than one variant, accounting for potential consistency or carryover effects across conditions. Lastly, $T_{1i}$ and $T_{2i}$ represent the specific pairwise topics compared within each analysis.


Given the complexity and hierarchical structure of the data, we employed a hierarchical Bayesian logistic regression model using a non-centered parameterization approach~\cite{mcelreath2018statistical}. Hierarchical modeling allows us to partially pool information across groups, such as different experimental conditions or topic pairingsâ€”improving the robustness and generalizability of estimates, particularly in the presence of sparse data. Non-centered parameterization further enhances sampling efficiency and stability by allowing model parameters to be less strictly influenced by the prior distributions, making the posterior distributions easier to sample~\cite{mcelreath2018statistical}.

Specifically, each experimental variable follows a hierarchical prior structure as outlined in Equation~\ref{eq:generic_non_center_hyper}:

\begin{equation}
    \label{eq:generic_non_center_hyper}
    x_i = \mu_x + \sigma_x \cdot \eta_i, \quad \eta_i \sim \mathcal{U}(0,1)
\end{equation}

Here, each variable ($x_i$) is drawn from a normal distribution centered around a group-level mean ($\mu_x$) and scaled by a group-level standard deviation ($\sigma_x$). For example, a full breakdown of $C_i$ is defined as: 

\begin{align}
    \label{eq:generic_non_center_hyper_C}
    \beta_c[c_i] = \beta_a + \sigma_c \cdot \eta[c_i], \quad \eta[c_i] \sim \mathcal{N}(0, 1)\\
    \sigma_c \sim \mathcal{U}(0,1), \quad \beta_a &\sim \mathcal{N}(0, 0.5)
\end{align}


Similar hierarchical structures are used for other experimental variables (order, prior alignment, and topic), differing only in their hyperpriors. Specifically, topics ($T_{1i}, T_{2i}$) utilize a narrower hyperprior ($\mathcal{N}(0,0.25)$) due to expected lower variability, while other experimental variables such as order and prior alignment employ broader hyperpriors ($\mathcal{N}(0,0.5)$).